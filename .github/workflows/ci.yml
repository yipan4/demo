name: CI
on: [push, pull_request]

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r app/requirements.txt

      # Run the app, but don't fail the job yet; capture logs
      - name: Run app (expected to fail first run)
        id: runapp
        continue-on-error: true
        run: |
          set +e
          python app/app.py > run.out 2> run.err
          code=$?
          echo "exit_code=$code" >> $GITHUB_OUTPUT
          echo "err<<EOF" >> $GITHUB_OUTPUT
          tail -n 120 run.err >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      # Use Azure OpenAI to generate a dynamic summary
      - name: Summarize result with Azure OpenAI
        if: always()
        id: ai
        env:
          AOAI_ENDPOINT: ${{ secrets.AOAI_ENDPOINT }}
          AOAI_KEY: ${{ secrets.AOAI_KEY }}
          AOAI_DEPLOYMENT: ${{ secrets.AOAI_DEPLOYMENT }}
          OUTCOME: ${{ steps.runapp.outcome }}
        run: |
          # Set and export environment variables for the Python script to use
          export STATUS="${OUTCOME}"
          if [ "$STATUS" = "failure" ]; then
            export CONTEXT="${{ steps.runapp.outputs.err }}"
          else
            export CONTEXT="Build passed. Dependencies OK."
          fi

          # Build a clear prompt
          cat > prompt.txt <<'P'
          You are a CI assistant. Analyze the build outcome and error logs,
          explain the LIKELY root cause in one sentence, then propose ONE precise fix
          line for requirements.txt if applicable. Keep it under 4 lines total.
          P

          # Debug environment variables to verify they're set
          echo "Debug: STATUS=$STATUS"
          echo "Debug: CONTEXT length=$(echo "$CONTEXT" | wc -c)"
          
          # Execute the external Python script and capture the output
          # The script will print to GITHUB_OUTPUT format with the summary<<EOF syntax
          python ai/generate_summary.py >> $GITHUB_OUTPUT

      # Notify Power Automate regardless of outcome, with AI summary text
      - name: Notify Power Automate (Teams) about result
        if: always()
        env:
          FLOW_URL: ${{ secrets.PA_FLOW_URL }}
          REPO: ${{ github.repository }}
          BRANCH: ${{ github.ref_name }}
          RUN_URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
          OUTCOME: ${{ steps.runapp.outcome }}
          AI_SUMMARY: ${{ steps.ai.outputs.summary }}
        run: |
          set -e
          STATUS="${OUTCOME}"
          if [ "$STATUS" = "failure" ]; then
            TITLE="CI Failure"
            COLOR="D93F0B"
          else
            TITLE="CI Success"
            COLOR="36A64F"
          fi
          TEXT="${AI_SUMMARY:-Build result summary unavailable.}"

          # Create JSON payload
          JSON_PAYLOAD='{"title":"'"${TITLE}: ${REPO} (${BRANCH})"'","text":"'"${TEXT}"'","color":"'"${COLOR}"'","run_url":"'"${RUN_URL}"'","repo":"'"${REPO}"'","branch":"'"${BRANCH}"'","status":"'"${STATUS}"'"}'
          
          # Send to Power Automate using HTTP Webhook
          # With HTTP Webhook, authentication is built into the URL, so no additional auth headers needed
          curl -sS -H "Content-Type: application/json" -d "${JSON_PAYLOAD}" "${FLOW_URL}" || true

      # Keep run status accurate (first run should be red)
      - name: Enforce failure if app failed
        if: steps.runapp.outcome == 'failure'
        run: exit 1
